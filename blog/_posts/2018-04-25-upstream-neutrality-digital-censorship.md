---
title: Sorry, Reality Violates Our Community Guidelines
layout: post
author: Nate Levesque
tags: [upstream-neutrality]
head-image: chat-bubbles.png
---

Censoring content—whatever the reason, be it for keeping adult content out of the hands of minors, because of manufactured outrage, or any other reason—is an interesting dilemma when it comes to digital content. Parental controls aren't exactly new or complicated, and online services are increasingly adding "kid-friendly" restricted versions of their services. For the most part, those restrictions aren't anything too novel as far as gated content is concerned. However, digital bans are more enforceable and certain formats of content can be modified on the fly with surgical precision. We might not always know it's happening or why since sometimes the only reason for a takedown is a violation of "community guidelines."

China is one of the most cited examples of digital censorship (though there are other countries with similar policies including Turkey). China's Internet is controlled by the state and exists within what's referred to colloquially as "The Great Firewall of China." The government restricts access to all manner of online content and services, sometimes blocking entire sites and other times only blocking specific pages. For the layman there isn't any way around the content blocking and for those who know how to circumvent the blocks, doing so is illegal. By controlling what parts of the Internet are available, China is able to almost completely ban content from being seen within the country. This is different from, for example, banning books because book bans cannot round up every copy of a book. China, however, can instantly block information from the entire country in totality.

It isn't only governments that censor content. Online services do so for the sake of interest targeting and for PR reasons. Facebook, which posts case studies of running advertisements on its service, [quietly hid pages](https://theintercept.com/2018/03/14/facebook-election-meddling/) that suggested it might have the ability to influence elections. When asked if they could have influenced the 2016 election outcome, Facebook of course denied. To back up their point, an entire section for "Government and Politics" case studies disappeared from Facebook's success stories list. To be fair, it's within the right of any website to take down pages or links to pages on a whim though Facebook's timing may have been unfortunate.

Making things disappear is only one way to censor digital content. Some media formats, such as ebooks, are fairly easy to modify—permanently or "on the fly." Censored content in video and audio is relatively obvious; blanked (or "bleeped") vocals or blurred images, and we're all accustomed to it. An e-reading app called "Clean Reader" [tried to extend the same feature](https://www.techradar.com/news/world-of-tech/content-in-moderation-is-digital-censorship-messing-with-the-arts-1289740) to ebooks a few years ago. Clean Reader, without permission from authors, allowed readers to choose how "clean" they wanted a text to be and the app would blank out and replace words that were offensive according to the user's settings (though, the creators make very clear, the app did not sell modified books).

Clean Reader's approach is simplistic, a sort of automated find-and-replace for things it deems inappropriate. There are much more complex systems at work trying to keep the Internet clean which do far more than find-and-replace. YouTube has software that scans every video uploaded for copyright and content problems. [Between October and December 2017](https://youtube.googleblog.com/2018/04/more-information-faster-removals-more.html), YouTube's algorithms flagged 6.7 million videos for review and of those, 76% were removed before anyone watched them. The service [has removed everything from](https://motherboard.vice.com/en_us/article/59jgka/a-brief-history-of-youtube-censorship) "Tide Pod Challenges" to adult content to videos of violent extremism. Video removals aren't all good news though. While Google publishes community guidelines, what types of videos Google decides aren't suitable for YouTube is decided by YouTube with no real oversight, aside from community outrage which the company occasionally ignores.

Though censoring content in some ways may keep the Internet clean, it also might be hiding the realities from the world from us, thereby hurting our ability to be informed. In 2017, [YouTube faced outcry](https://www.nytimes.com/2017/08/22/world/middleeast/syria-youtube-videos-isis.html) for accidentally censoring videos showing atrocities in Syria. While the videos were graphic, they're the work of organizations trying to document human rights violations that are happening. In some ways, we're losing our ability to choose what we see and it's limiting how informed we are. As big tech companies increasingly become distributors of news, we need a change to our culture and oversight of keeping the Internet clean. The realities of the world don't match with the community guidelines of various online services and our filter bubble will get harder to escape when reality is actively censored instead of simply not being "recommended" to us.